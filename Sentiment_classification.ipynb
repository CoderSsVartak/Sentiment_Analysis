{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVQuVO8raNWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Dropout\n",
        "from tensorflow.keras import Input, Model\n",
        "import gensim.downloader as api\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import time\n",
        "\n",
        "#Download the nltk packages required\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD_CrGpvawT_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7ecc5515-5826-4a96-b952-443d4b1c17aa"
      },
      "source": [
        "#Download word embeddings\n",
        "#vocabulary of 40k words each with 100 parameters\n",
        "word_vec = api.load('glove-wiki-gigaword-100')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA_UcbnNbP55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word_encoder(word_vec):\n",
        "\n",
        "    #key: word, value: number in the vocabulary\n",
        "    word_to_enc = dict((word, (i+2)) for i, word in enumerate(word_vec.wv.vocab))\n",
        "    #value: word, key: number in the vocabulary\n",
        "    enc_to_word = dict(((i+2), word) for i, word in enumerate(word_vec.wv.vocab))\n",
        "\n",
        "    #0 is used for padding and 1 is used for out of vocab keywords\n",
        "    word_to_enc[''], word_to_enc['UNK'] = 0, 1\n",
        "    enc_to_word[0], enc_to_word[1] = '', 'UNK'\n",
        "\n",
        "    return word_to_enc, enc_to_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrtwKOx4cGev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(word_vec):\n",
        "\n",
        "    embeddings = np.zeros((len(word_vec.wv.vocab)+2, 100))\n",
        "    for i, word in enumerate(word_vec.wv.vocab):\n",
        "        embeddings[i+2] = word_vec[word]\n",
        "    \n",
        "    return embeddings\n",
        "\n",
        "def create_embedding_layer(word_vec, embeddings, output_dimensions, trainable=False):\n",
        "    #Create an Embedding Layer\n",
        "    embedding_layer = Embedding(\n",
        "        input_dim = len(word_vec.wv.vocab)+2,\n",
        "        output_dim = output_dimensions,\n",
        "        weights = [embeddings],\n",
        "        trainable = trainable\n",
        "    )\n",
        "\n",
        "    return embedding_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBG7ecaaeIpj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "8d7f746e-7137-40fc-8152-e2ce22fc3c51"
      },
      "source": [
        "embeddings = get_embeddings(word_vec)\n",
        "word_to_enc, enc_to_word = get_word_encoder(word_vec)\n",
        "embedding_layer = create_embedding_layer(word_vec, embeddings, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQmMuvrZeS4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading the dataset using which is stored in a pickle file\n",
        "filepath = '/content/twitter_data.pickle'\n",
        "with open(filepath, 'rb') as file:\n",
        "    data = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdJaju7-iQJX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "3873d777-dc85-4b75-a25c-c630c00dc70d"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048570</th>\n",
              "      <td>4</td>\n",
              "      <td>My GrandMa is making Dinenr with my Mum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048571</th>\n",
              "      <td>4</td>\n",
              "      <td>Mid-morning snack time... A bowl of cheese noo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048572</th>\n",
              "      <td>4</td>\n",
              "      <td>@ShaDeLa same here  say it like from the Termi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048573</th>\n",
              "      <td>4</td>\n",
              "      <td>@DestinyHope92 im great thaanks  wbuu?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048574</th>\n",
              "      <td>4</td>\n",
              "      <td>cant wait til her date this weekend</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1048575 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Target                                              Tweet\n",
              "0             0  is upset that he can't update his Facebook by ...\n",
              "1             0  @Kenichan I dived many times for the ball. Man...\n",
              "2             0    my whole body feels itchy and like its on fire \n",
              "3             0  @nationwideclass no, it's not behaving at all....\n",
              "4             0                      @Kwesidei not the whole crew \n",
              "...         ...                                                ...\n",
              "1048570       4           My GrandMa is making Dinenr with my Mum \n",
              "1048571       4  Mid-morning snack time... A bowl of cheese noo...\n",
              "1048572       4  @ShaDeLa same here  say it like from the Termi...\n",
              "1048573       4             @DestinyHope92 im great thaanks  wbuu?\n",
              "1048574       4               cant wait til her date this weekend \n",
              "\n",
              "[1048575 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnF7egcCGBlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Drop negative data row ie. the first 0.5 million rows for balancing the classes of the dataset\n",
        "data = data[550000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzCbQVueeVST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array(data['Tweet'])\n",
        "y = np.array(data['Target'])/4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5FnVSXAsdpj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6324e46f-c733-4b36-f041-548441bfbabb"
      },
      "source": [
        "#output the ratio of positive classes\n",
        "print(list(y).count(1)/len(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2370607729537706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrCMi3Quetob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data cleaning and vectorizing\n",
        "def clean_data(texts):\n",
        "    \n",
        "    for idx in range(len(texts)):\n",
        "        #Remove the special symbols, multiple spaces should be replaced by a single space\n",
        "        #lower the letters of the words\n",
        "\n",
        "        texts[idx] = re.sub(r'\\W', ' ', texts[idx])\n",
        "        texts[idx] = re.sub(r' +', ' ', texts[idx])\n",
        "        texts[idx] = texts[idx].lower()\n",
        "    \n",
        "    return np.array(texts)\n",
        "\n",
        "#Convert the sentences into numbers for the embedding layer\n",
        "#texts is the tweets and max_length is the max_length of the output array per sentence\n",
        "def vectorizer(texts, max_length=50, remove_stopwords=True):\n",
        "\n",
        "    temp_texts = []\n",
        "    #Remove stopwords as they don't convey much meaning.\n",
        "    #works well when max_length is not to be kept too high\n",
        "    if remove_stopwords:\n",
        "        stop_words = set(stopwords.words('english')) \n",
        "    \n",
        "    for sent in texts:\n",
        "        sent = word_tokenize(sent)\n",
        "        nos = [0 for _ in range(max_length)]\n",
        "        counter = 0\n",
        "        for word in range(len(sent)):\n",
        "            \n",
        "            #If stopwords are not to be removed\n",
        "            if not remove_stopwords:\n",
        "                try:\n",
        "                    nos[counter] = word_to_enc[sent[word]]\n",
        "                except KeyError:\n",
        "                    try:\n",
        "                        nos[counter] = 1\n",
        "                    except IndexError:\n",
        "                        pass\n",
        "                except IndexError:\n",
        "                    pass\n",
        "                counter += 1\n",
        "\n",
        "            #If stopwords are to be removed and word is not present in stopword\n",
        "            elif not sent[word] in stop_words:\n",
        "                try:\n",
        "                    nos[counter] = word_to_enc[sent[word]]\n",
        "                except KeyError:\n",
        "                    try:\n",
        "                        nos[counter] = 1\n",
        "                    except IndexError:\n",
        "                        pass\n",
        "                except IndexError:\n",
        "                    pass\n",
        "                counter += 1\n",
        "                \n",
        "        temp_texts.append(np.array(nos))\n",
        "    \n",
        "    return np.array(temp_texts)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEK-aanpkzD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(input_sequence_length):\n",
        "\n",
        "    x_input = Input(shape=(input_sequence_length, ), dtype='int64')\n",
        "\n",
        "    x = embedding_layer(x_input)\n",
        "\n",
        "    #1st LSTM Layer\n",
        "    x = LSTM(32, return_sequences=True)(x)\n",
        "    x = Dropout(0.8)(x)\n",
        "\n",
        "    #2nd LSTM Layer\n",
        "    x = LSTM(16, return_sequences=True)(x)\n",
        "    x = Dropout(0.8)(x)\n",
        "\n",
        "\n",
        "    #3rd LSTM layer\n",
        "    x = LSTM(16, activation='relu')(x)\n",
        "\n",
        "    #Dense Layer\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "\n",
        "    #Output Layer\n",
        "    pred = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(x_input, pred, name='Classifier')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NLcoN9om8m_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "9b937ac2-fa25-473c-bd17-34eda9c4dcc6"
      },
      "source": [
        "sent_model = model(20)\n",
        "sent_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Classifier\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_15 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 20, 100)           40000200  \n",
            "_________________________________________________________________\n",
            "lstm_38 (LSTM)               (None, 20, 32)            17024     \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 20, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm_39 (LSTM)               (None, 20, 16)            3136      \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 20, 16)            0         \n",
            "_________________________________________________________________\n",
            "lstm_40 (LSTM)               (None, 16)                2112      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 40,023,049\n",
            "Trainable params: 22,849\n",
            "Non-trainable params: 40,000,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67PaXA4HnoJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split dataset into train(90%)-dev(7%)-val(3%) sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
        "x_dev, x_val, y_dev, y_val = train_test_split(x_test, y_test, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNAB1vjqrLa8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0610f672-a898-4291-843f-9df28eb7932e"
      },
      "source": [
        "print(list(y_train).count(1)/len(y_train))\n",
        "print(list(y_dev).count(1)/len(y_dev))\n",
        "print(list(y_val).count(1)/len(y_val))\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_dev.shape, y_dev.shape)\n",
        "print(x_val.shape, y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.23701491019023713\n",
            "0.23811989100817438\n",
            "0.2359654142030644\n",
            "(943717,) (943717,)\n",
            "(73400,) (73400,)\n",
            "(31458,) (31458,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U85Z7lds36n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9ca55be-dfd9-4c8f-fe4e-fb136c51e8db"
      },
      "source": [
        "#Clean and vectorize the data\n",
        "x_train = vectorizer(clean_data(x_train), max_length=20)\n",
        "x_dev = vectorizer(clean_data(x_dev), max_length=20)\n",
        "x_val = vectorizer(clean_data(x_val), max_length=20)\n",
        "\n",
        "print(x_train.shape, x_dev.shape, x_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(943717, 20) (73400, 20) (31458, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7ZeHjm4rz-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy',\n",
        "                                                                         tf.keras.metrics.TruePositives(thresholds=0.7),\n",
        "                                                                         tf.keras.metrics.TrueNegatives(),\n",
        "                                                                         tf.keras.metrics.FalseNegatives(),\n",
        "                                                                         tf.keras.metrics.FalsePositives()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZuWbQYYsubj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "6c7e79e0-55a4-4883-fc24-cdc98cac7302"
      },
      "source": [
        "sent_model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_dev, y_dev), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "7373/7373 [==============================] - 232s 31ms/step - loss: 0.3901 - accuracy: 0.8252 - true_positives_16: 58536.0000 - true_negatives_7: 676560.0000 - false_negatives_5: 121482.0000 - false_positives: 43482.0000 - val_loss: 0.3905 - val_accuracy: 0.8268 - val_true_positives_16: 5209.0000 - val_true_negatives_7: 51756.0000 - val_false_negatives_5: 8548.0000 - val_false_positives: 4166.0000\n",
            "Epoch 2/10\n",
            "7373/7373 [==============================] - 233s 32ms/step - loss: 0.3884 - accuracy: 0.8259 - true_positives_16: 58990.0000 - true_negatives_7: 676937.0000 - false_negatives_5: 121154.0000 - false_positives: 43105.0000 - val_loss: 0.3869 - val_accuracy: 0.8274 - val_true_positives_16: 4627.0000 - val_true_negatives_7: 52603.0000 - val_false_negatives_5: 9351.0000 - val_false_positives: 3319.0000\n",
            "Epoch 3/10\n",
            "7373/7373 [==============================] - 232s 31ms/step - loss: 0.3876 - accuracy: 0.8265 - true_positives_16: 59333.0000 - true_negatives_7: 676765.0000 - false_negatives_5: 120467.0000 - false_positives: 43277.0000 - val_loss: 0.3878 - val_accuracy: 0.8277 - val_true_positives_16: 4586.0000 - val_true_negatives_7: 52451.0000 - val_false_negatives_5: 9174.0000 - val_false_positives: 3471.0000\n",
            "Epoch 4/10\n",
            "7373/7373 [==============================] - 236s 32ms/step - loss: 0.3870 - accuracy: 0.8266 - true_positives_16: 59285.0000 - true_negatives_7: 676607.0000 - false_negatives_5: 120185.0000 - false_positives: 43435.0000 - val_loss: 0.3864 - val_accuracy: 0.8277 - val_true_positives_16: 4925.0000 - val_true_negatives_7: 52325.0000 - val_false_negatives_5: 9052.0000 - val_false_positives: 3597.0000\n",
            "Epoch 5/10\n",
            "7373/7373 [==============================] - 233s 32ms/step - loss: 0.3865 - accuracy: 0.8270 - true_positives_16: 59570.0000 - true_negatives_7: 676631.0000 - false_negatives_5: 119834.0000 - false_positives: 43411.0000 - val_loss: 0.3906 - val_accuracy: 0.8279 - val_true_positives_16: 5058.0000 - val_true_negatives_7: 51721.0000 - val_false_negatives_5: 8434.0000 - val_false_positives: 4201.0000\n",
            "Epoch 6/10\n",
            "7373/7373 [==============================] - 232s 31ms/step - loss: 0.3858 - accuracy: 0.8277 - true_positives_16: 59889.0000 - true_negatives_7: 676512.0000 - false_negatives_5: 119114.0000 - false_positives: 43530.0000 - val_loss: 0.3849 - val_accuracy: 0.8269 - val_true_positives_16: 4077.0000 - val_true_negatives_7: 53278.0000 - val_false_negatives_5: 10060.0000 - val_false_positives: 2644.0000\n",
            "Epoch 7/10\n",
            "7373/7373 [==============================] - 235s 32ms/step - loss: 0.3853 - accuracy: 0.8279 - true_positives_16: 59881.0000 - true_negatives_7: 676688.0000 - false_negatives_5: 119055.0000 - false_positives: 43354.0000 - val_loss: 0.3908 - val_accuracy: 0.8277 - val_true_positives_16: 5332.0000 - val_true_negatives_7: 51398.0000 - val_false_negatives_5: 8124.0000 - val_false_positives: 4524.0000\n",
            "Epoch 8/10\n",
            "7373/7373 [==============================] - 232s 31ms/step - loss: 0.3850 - accuracy: 0.8282 - true_positives_16: 59964.0000 - true_negatives_7: 676117.0000 - false_negatives_5: 118177.0000 - false_positives: 43925.0000 - val_loss: 0.3851 - val_accuracy: 0.8291 - val_true_positives_16: 4884.0000 - val_true_negatives_7: 52265.0000 - val_false_negatives_5: 8886.0000 - val_false_positives: 3657.0000\n",
            "Epoch 9/10\n",
            "7373/7373 [==============================] - 234s 32ms/step - loss: 0.3846 - accuracy: 0.8284 - true_positives_16: 60067.0000 - true_negatives_7: 676247.0000 - false_negatives_5: 118179.0000 - false_positives: 43795.0000 - val_loss: 0.3840 - val_accuracy: 0.8292 - val_true_positives_16: 4635.0000 - val_true_negatives_7: 52689.0000 - val_false_negatives_5: 9301.0000 - val_false_positives: 3233.0000\n",
            "Epoch 10/10\n",
            "7373/7373 [==============================] - 234s 32ms/step - loss: 0.3841 - accuracy: 0.8286 - true_positives_16: 60342.0000 - true_negatives_7: 676307.0000 - false_negatives_5: 118006.0000 - false_positives: 43735.0000 - val_loss: 0.3873 - val_accuracy: 0.8291 - val_true_positives_16: 5378.0000 - val_true_negatives_7: 51537.0000 - val_false_negatives_5: 8159.0000 - val_false_positives: 4385.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4c07d3efd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEu1klrEtPpQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2d8fa464-9273-4090-f13f-cb4a70a0a9d1"
      },
      "source": [
        "metrics = sent_model.evaluate(x_val, y_val, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "492/492 [==============================] - 4s 7ms/step - loss: 0.3896 - accuracy: 0.8269 - true_positives_16: 2233.0000 - true_negatives_7: 22154.0000 - false_negatives_5: 3563.0000 - false_positives: 1881.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3ErXAbT8Zfi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "8892831b-e4d1-4fad-e7f5-6a8efb531ab4"
      },
      "source": [
        "print(\"Total elements: \", len(x_val))\n",
        "print(\"Total positives: \", list(y_val).count(1)/ len(x_val)*100, \"%\")\n",
        "print(\"Total Negatives: \", list(y_val).count(0)/ len(x_val)*100, \"%\")\n",
        "print(\"True Positive: \", metrics[2]/ list(y_val).count(1)*100, \"%\")\n",
        "print(\"True Negative: \", metrics[3]/ list(y_val).count(0)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total elements:  31458\n",
            "Total positives:  23.59654142030644 %\n",
            "Total Negatives:  76.40345857969356 %\n",
            "True Positive:  30.08217701737842 %\n",
            "True Negative:  92.17391304347827 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv1iXz82IIEn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "2c94c48e-a362-4353-f1c6-e0e31c2782ae"
      },
      "source": [
        "sent_model.predict(x_val), y_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.32798773],\n",
              "        [0.71607465],\n",
              "        [0.12307593],\n",
              "        ...,\n",
              "        [0.57409924],\n",
              "        [0.4033209 ],\n",
              "        [0.8392886 ]], dtype=float32), array([0., 1., 0., ..., 1., 1., 0.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDGE7j6c7t-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make a prediction on a single tweet\n",
        "def predict(model, text):\n",
        "    \n",
        "\n",
        "    text = vectorizer(clean_data([text]), max_length=20)\n",
        "    text = np.reshape(text, (1, -1))\n",
        "    prediction = model.predict(text)\n",
        "    return prediction\n",
        "\n",
        "def multi_predict(model, tweets, show_time=True, pos_margin=0.7, neg_margin=0.3, return_values=False):\n",
        "    s = time.time()\n",
        "    pos, neg, neutral = 0, 0, 0\n",
        "\n",
        "    text = vectorizer(clean_data(tweets), max_length=20)\n",
        "    prediction = model.predict(text)\n",
        "\n",
        "    for pred in prediction:\n",
        "        if pred >= pos_margin:\n",
        "            pos += 1\n",
        "        elif pred >= neg_margin and pred < pos_margin:\n",
        "            neutral += 1\n",
        "        else:\n",
        "            neg += 1\n",
        "\n",
        "    if show_time:\n",
        "        print(f'Total Time taken for {tweets.shape[0]}: {time.time()-s}')\n",
        "\n",
        "    if return_values:\n",
        "        return prediction\n",
        "        \n",
        "    return {\"Positive Tweets\":pos, \"Negative Tweets\":neg, \"Neutral Tweets\":neutral}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gcR7xJl9B_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "ca34520c-0a2d-4f3f-cd0a-76ac2e2545d0"
      },
      "source": [
        "#Build an end to end model\n",
        "\n",
        "input_data = Input(shape=(20,), dtype='int64')\n",
        "preds = sent_model(input_data)\n",
        "end_to_end_model = Model(input_data, preds, name='end_to_end_classifier')\n",
        "end_to_end_model.summary()\n",
        "end_to_end_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"end_to_end_classifier\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "Classifier (Functional)      (None, 1)                 40023049  \n",
            "=================================================================\n",
            "Total params: 40,023,049\n",
            "Trainable params: 22,849\n",
            "Non-trainable params: 40,000,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USArNPQU9IHK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "3487f6d4-215f-46ba-da2b-57c47eb0aac0"
      },
      "source": [
        "#test_data = \"I am a very huge fan of the performing arts. i am very good at live performance\"\n",
        "#test_data = \"You motherfucker son of a bitch. We all hate you\"\n",
        "#test_data = \"I am very bad at predicting the mood swings of people\"\n",
        "#test_data = \"This is a generic tweet.\"\n",
        "#test_data = data[100:200]\n",
        "#tweets = np.array(test_data['Tweet'])\n",
        "#print(\"Total Tweets: \", tweets.shape)\n",
        "\n",
        "multi_predict(end_to_end_model, tweets, pos_margin=0.5, neg_margin=0.5, return_values=True)\n",
        "predict(end_to_end_model, test_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Tweets:  (100,)\n",
            "Total Time taken for 100: 0.08659529685974121\n",
            "[0.87100685] 2\n",
            "[0.80267394] 5\n",
            "[0.94494665] 24\n",
            "[0.83507645] 29\n",
            "[0.79905856] 41\n",
            "[0.7000853] 47\n",
            "[0.80914414] 51\n",
            "[0.8387081] 52\n",
            "[0.8860167] 65\n",
            "[0.8946146] 69\n",
            "[0.9692976] 80\n",
            "[0.7392249] 82\n",
            "[0.88025963] 87\n",
            "[0.9175091] 91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr4d6BJgASmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_model = model(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niqh5rSs-cz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_model.load_weights('/content/sentiment_classifier_v1.20.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpz_FyggLcHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "5d701fba-151e-4d99-a8bb-910b2c38f4fc"
      },
      "source": [
        "from systemml.mllearn import Keras2DML"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a4b144071a6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msystemml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKeras2DML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'systemml'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrR86FskLd_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from systemml.mllearn im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCfdxuC_LxiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}